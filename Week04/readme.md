# Week 4 — Text in Processing & Finishing our HoL video

In this live coding session we put the words in code+words! After doing some processing tutorials in my own time, it was exciting to be able to apply the exact same principles to text.

<img src="testtext.png">

<p align="center"><img src="TopsyTurvy.gif"></p>

## Second Life —

Last week my group (Finn, Tayla, Taj and I) had a 3 hour session to record the different scenes in Second Life we had roughly planned out. However, soon after we realised that the screen recordings were pretty terrible (frame rate wise, as well as being very out of sync with our text-to-voice generator). We were a bit tempted to keep the tacky-ness of these clips, but also felt that it was too distracting combined with the other bizarre elements we incorporated. With Second Life's eerily realistic graphics, we knew the potential for an evocative, cinematic performance was there, and were determined to grasp it.

We decided to reshoot after a few days, after more thorough planning in our shared Google doc. We had a script each and had chosen specific characters from the [text-to-voice generator](https://tetyys.com/SAPI4/) we were using for each of the characters. We planned to shoot the scenes while playing the voices in real time, so the avatars could move their mouths in sync with the script, which we would later edit over the videos.

This worked very successfully! Reshooting was a great choice, in my opinion, especially as we became well-practiced with camera controls, environment settings, and locations offered in Second Life. It also pushed us to plan meticulously, with a script and chosen locations before we began shooting. It still took a while, and we did undergo some technical difficulties. It was so much fun, and Second Life is an inherently mind-boggling and highly amusing place. Other than filming, we also went virtual-clubbing together and got kicked out of a location.

After this, we took a collaborative approach to editing. Each of us screen recorded certain sections of the video, and would edit it ourselves before compiling it together into one. This was super interesting as we had never seen the footage or perspective of the other group-members as they filmed, and had to wait for the compilation to see how the entire video turned out. it was amazing, and mostly hilarious, to watch the outcome. I was truly impressed.

## Poem Field No. 1 (1967)

[Poem Field No. 1](https://www.youtube.com/watch?v=OsNmrCgwwQM) is an early computer animation from Stan VanDerBeek and Ken Knowlton in 1967. My sister showed it to me one day, and I just found it jaw-dropping. It's a silent film, made using Ken Knowlton's BEFLIX language and conceived by visual artist Stan VanDerBeek. This was part of a program at Bell Labs which had early computer scientists collaborating with artists.

The visual transitions and effects makes this poetry reading experience overwhelmingly visceral and memorable. There is a beauty in being able to watch pixels moving around, conveying meanings of words, creating illusions of layers, and fascinating abstract shapes. How come I don't know how to do that in 2020??

As soon as I saw this I was reminded of our session on Modular Typography. When you can see how a designer/artist has chosen to convey a message using basic units, you're let in on at least a sliver of their mode of thinking, and realise how genius those choices really are.

<img src="PoemField.jpg"><img src="Place.jpg">


___

## [WEEK 03](https://jackieliiu.github.io/CODEWORDS/Week03/) | [WEEK 05](https://jackieliiu.github.io/CODEWORDS/Week05/)
